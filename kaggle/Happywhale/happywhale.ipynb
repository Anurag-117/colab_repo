{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 🐳Happywhale 🐬\nIdentify and group all images that contain the same individual through time.","metadata":{}},{"cell_type":"markdown","source":"# Initial Setup","metadata":{}},{"cell_type":"markdown","source":"## Importing libraries","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_addons as tfa\nimport pandas as pd\nimport numpy as np\nimport sklearn\n\n# import cudf, cupy, cuml\n# from cuml.neighbors import NearestNeightbors\n# from cuml.manifold import TSNE, PCE\n\nimport imageio\nimport gc\nimport random\nfrom tqdm.notebook import tqdm\n\ntqdm.pandas()\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nimport matplotlib.patches as patches\nfrom matplotlib import animation, rc\nimport plotly.graph_objects as go\nimport seaborn as sns\nimport plotly.express as px\nimport PIL\nimport plotly\nimport cv2\nfrom PIL import Image, ImageEnhance\nimport plotly.io as pio\nprint(pio.renderers)\n\nprint(f\"TensorFlow version: {tf.__version__}\")\nprint(f\"TensorFlow addons version: {tfa.__version__}\")\nprint(f\"SkLearn version: {sklearn.__version__}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-01T16:10:32.126095Z","iopub.execute_input":"2022-03-01T16:10:32.126970Z","iopub.status.idle":"2022-03-01T16:10:32.152470Z","shell.execute_reply.started":"2022-03-01T16:10:32.126922Z","shell.execute_reply":"2022-03-01T16:10:32.151649Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(\"Notebbook Color Scheme:\")\ncolor_palette = sns.color_palette(\"viridis\", as_cmap=True)\n\nsns.color_palette(\"viridis\")","metadata":{"execution":{"iopub.status.busy":"2022-03-01T16:10:32.156465Z","iopub.execute_input":"2022-03-01T16:10:32.156980Z","iopub.status.idle":"2022-03-01T16:10:32.166804Z","shell.execute_reply.started":"2022-03-01T16:10:32.156945Z","shell.execute_reply":"2022-03-01T16:10:32.165771Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class color:\n   GREEN = '\\033[92m'\n   BOLD = '\\033[1m'\n   END = '\\033[0m'\n    \nclass Config:\n    import os\n    ROOT_LOGDIR = os.path.join(os.curdir, \"logdir\") # Logs dir\n\n    def __init__(self, project=None, model=None,\n                 disable_wandb=False, seed=42):\n        import os\n        import time\n        import wandb\n        import json\n        import random\n        \n        self.DISABLE_WANDB = disable_wandb\n        self.BATCH_SIZE = 32\n        self.FOLD = 4\n        self.EPOCHS = 30\n        self.MODEL_PATH = f\"{model}.h5\"     \n        \n        \"\"\" Attempt to be Reproducible \"\"\"\n        os.environ['PYTHONHASHSEED'] = str(seed)\n        random.seed(seed)\n        np.random.seed(seed)\n        tf.random.set_seed(seed)\n\n        \n        \"\"\"Get the current run logdir inside root_logdir and run_id\n           Weights and Bias experiment tracking\"\"\"\n        self.run_id = model + time.strftime(\"-run_%Y_%m_%d-%H_%M_%S\") if model else time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")            \n        if not disable_wandb: \n            self.WANDB_RUN = wandb.init(project=project, name=self.run_id, config=vars(self),\n                                        sync_tensorboard=True)\n            self.TENSORBOARD_LOGDIR = os.path.join(Config.ROOT_LOGDIR, self.run_id)\n            \n        print(color.BOLD + 'Config created with run ID: ' + color.END + color.BOLD + color.GREEN + self.run_id + color.END)\n        \n    def log_artifact(self, artifact_name, type_, file_path):\n        \"\"\"Log a artifact like preprocess file to wandb\"\"\"\n        if self.DISABLE_WANDB: return\n        artifact = wandb.Artifact(artifact_name, type=type_)\n        artifact.add_file(file_path)\n        self.WANDB_RUN.log_artifact(artifact)\n    \n    def finish(self):\n        \"\"\"Call this function to finish this run/experiment\"\"\"\n        self.WANDB_RUN.finish()\n        \n        \nconfig = Config(project='Happywhale', model='')","metadata":{"execution":{"iopub.status.busy":"2022-02-27T15:17:54.265273Z","iopub.execute_input":"2022-02-27T15:17:54.265562Z","iopub.status.idle":"2022-02-27T15:18:05.028241Z","shell.execute_reply.started":"2022-02-27T15:17:54.265532Z","shell.execute_reply":"2022-02-27T15:18:05.027058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation\n## Metadata Cleaning\n**Species column typos adjustment**\n- `bottlenose_dolpin` -> `bottlenose_dolphin`\n- `kiler_whale` -> `killer_whale`\n- `beluga` -> `beluga_whale`\n- `globis` & `pilot_whale` -> `short_finned_pilot_whale` (due to extreme similarities [according to this discussion](https://www.kaggle.com/c/happy-whale-and-dolphin/discussion/305909)","metadata":{}},{"cell_type":"code","source":"# Importing the training data\ntrain_df = pd.read_csv(\"../input/happy-whale-and-dolphin/train.csv\")\n\n# Adjust typos in \"species\" column\ntrain[\"species\"] = train[\"species\"].replace({\n    \"bottlenose_dolphin\": \"bottlenode_dolphin\",\n    \"kiler_whale\": \"killer_whale\",\n    \"beluga\": \"beluga_whale\",\n    \"globis\": \"short_finned_pilot_whale\",\n    \"pilot_whale\": \"short_finned_pilot_whale\"\n})\n\n# Create a \"class\" columns\ntrain[\"class\"] = train[\"species\"].applu(lambda x: x.split(\"_\")[-1])\n\n# Train path\nTRAIN_PATH = \"../input/happy-whale-and-dolphin/train_images/\"\ntrain[\"path\"] = TRAIN_PATH + train[\"image\"]\n\n","metadata":{},"execution_count":null,"outputs":[]}]}